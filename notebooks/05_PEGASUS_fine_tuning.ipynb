{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1xFhcs0WFC8MPk2kfRApYEXXAf1Ltncu9","authorship_tag":"ABX9TyM1V5BU8j1E/G93XYVZrmcn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## ***Model Training - PEGASUS***"],"metadata":{"id":"Gndmh0Dg7F52"}},{"cell_type":"code","source":["!pip install datasets evaluate rouge_score bert_score"],"metadata":{"id":"1sF7L2vbACUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ts1t5V8j6rif"},"outputs":[],"source":["#importinig the libraries\n","import pandas as pd\n","import numpy as np\n","from datasets import Dataset\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","import evaluate\n","from rouge_score import rouge_scorer\n","import torch"]},{"cell_type":"code","source":[],"metadata":{"id":"4AbS0Dsr8GoX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_path = \"/content/drive/MyDrive/MScDissertation-Sonu/data/processed/train_processed.csv\"\n","valid_path = \"/content/drive/MyDrive/MScDissertation-Sonu/data/processed/validation_processed.csv\"\n","df_train = pd.read_csv(train_path)\n","df_valid = pd.read_csv(valid_path)\n","train_text_data = Dataset.from_pandas(df_train[['input_text', 'target_text']])\n","valid_text_data = Dataset.from_pandas(df_valid[['input_text', 'target_text']])"],"metadata":{"id":"hghYHVem7R9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_name = \"google/pegasus-xsum\"\n","tknzr = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"],"metadata":{"id":"YdtqQG1b7UL-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#tokenizing the data..\n","max_input_length = 512\n","max_target_length = 256\n","\n","def prprcs_fun(examples):\n","  model_inputs = tknzr(examples['input_text'], max_length=max_input_length, truncation=True)\n","  with tknzr.as_target_tokenizer():\n","    labels = tknzr(examples['target_text'], max_length=max_target_length, truncation=True)\n","  model_inputs['labels'] = labels['input_ids']\n","  return model_inputs\n","\n","tokenized_train = train_text_data.map(prprcs_fun, batched=True,remove_columns=train_text_data.column_names)\n","tokenized_valid = valid_text_data.map(prprcs_fun, batched=True,remove_columns=valid_text_data.column_names)\n"],"metadata":{"id":"qE3zsnvT7fhn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","model_output_dir = \"/content/drive/MyDrive/MScDissertation-Sonu/models/pegasus-xsum\"\n","\n","args = Seq2SeqTrainingArguments(output_dir=model_output_dir,eval_strategy=\"epoch\",\n","    learning_rate=2e-5,per_device_train_batch_size=batch_size,per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,save_total_limit=3,num_train_epochs=10,predict_with_generate=True,logging_steps=50,)"],"metadata":{"id":"T204iToB7joS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rouge_metric = evaluate.load(\"rouge\")\n","bertscore = evaluate.load(\"bertscore\")\n","\n","def computeMtrx(eval_preds):\n","  preds, labels = eval_preds\n","  decoded_preds = tknzr.batch_decode(preds,skip_special_tokens=True)\n","  labels = np.where(labels != -100, labels, tknzr.pad_token_id)\n","  decoded_labels = tknzr.batch_decode(labels,skip_special_tokens=True)\n","\n","  rougeRslt = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n","  bertRslt = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n","  bertRslt = {\"bert_score_f1\":np.mean(bertRslt['f1'])*100}\n","  result = {**rougeRslt,**bertRslt}\n","  return {k: round(v,4) for k,v in result.items()}"],"metadata":{"id":"0dQruGMD7uui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#training the model...\n","data_collator = DataCollatorForSeq2Seq(tknzr,model=model)\n","trainer = Seq2SeqTrainer(model,args,train_dataset=tokenized_train,eval_dataset=tokenized_valid,data_collator=data_collator,\n","                         tokenizer=tknzr,compute_metrics=computeMtrx)\n","\n","print(\"starting training....\")\n","trainer.train()\n"],"metadata":{"id":"y8-srqs27wnJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_model_path = \"/content/drive/MyDrive/MScDissertation-Sonu/models/pegasus-xsum-final\"\n","trainer.save_model(final_model_path)"],"metadata":{"id":"4T6LYlcJ72TL"},"execution_count":null,"outputs":[]}]}